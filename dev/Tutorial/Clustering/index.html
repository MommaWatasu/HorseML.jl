<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Clustering · HorseML</title><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.044/juliamono.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.11/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="HorseML logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">HorseML</a></span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">Tutorial</span><ul><li><a class="tocitem" href="../Welcome/">Welcome to HorseML</a></li><li><a class="tocitem" href="../Getting_Started/">Getting Started</a></li><li><a class="tocitem" href="../Preprocessing/">Preprocessing</a></li><li><a class="tocitem" href="../Classifiers/">Classifiers</a></li><li class="is-active"><a class="tocitem" href>Clustering</a><ul class="internal"><li><a class="tocitem" href="#data-processing"><span>data processing</span></a></li><li><a class="tocitem" href="#Kmeans-method"><span>Kmeans method</span></a></li><li><a class="tocitem" href="#GMM(Gaussian-Mixture-Model)"><span>GMM(Gaussian Mixture Model)</span></a></li><li><a class="tocitem" href="#Xmeans"><span>Xmeans</span></a></li><li><a class="tocitem" href="#DBSCAN"><span>DBSCAN</span></a></li><li><a class="tocitem" href="#HDBSCAN"><span>HDBSCAN</span></a></li></ul></li><li><a class="tocitem" href="../Tree/">Tree</a></li><li><a class="tocitem" href="../NeuralNetwork/">NeuralNetwork</a></li></ul></li><li><span class="tocitem">Manual</span><ul><li><a class="tocitem" href="../../Manual/Preprocessing/">Preprocessing</a></li><li><a class="tocitem" href="../../Manual/LossFunction/">LossFunction</a></li><li><a class="tocitem" href="../../Manual/Regression/">Regression</a></li><li><a class="tocitem" href="../../Manual/Classification/">Classification</a></li><li><a class="tocitem" href="../../Manual/Clustering/">Clustering</a></li><li><a class="tocitem" href="../../Manual/NeuralNetwork/">NeuralNetwork</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Tutorial</a></li><li class="is-active"><a href>Clustering</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Clustering</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/MommaWatasu/HorseML.jl/blob/master/docs/src/Tutorial/Clustering.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Clustering"><a class="docs-heading-anchor" href="#Clustering">Clustering</a><a id="Clustering-1"></a><a class="docs-heading-anchor-permalink" href="#Clustering" title="Permalink"></a></h1><h2 id="data-processing"><a class="docs-heading-anchor" href="#data-processing">data processing</a><a id="data-processing-1"></a><a class="docs-heading-anchor-permalink" href="#data-processing" title="Permalink"></a></h2><p>In clustering, if data is randomly generated, it will not converge, so use data that has already been confirmed to converge. Get the test data with the following command:</p><pre><code class="nohighlight hljs">$ wget https://github.com/MommaWatasu/HorseML.jl/raw/master/test/clustering.csv</code></pre><p>Once you get it, let&#39;s load it with Julia.</p><pre><code class="nohighlight hljs">using CSV
using DataFrames

df = CSV.read(&quot;clustering.csv&quot;, DataFrame, header=false)
x = Array(df)</code></pre><h2 id="Kmeans-method"><a class="docs-heading-anchor" href="#Kmeans-method">Kmeans method</a><a id="Kmeans-method-1"></a><a class="docs-heading-anchor-permalink" href="#Kmeans-method" title="Permalink"></a></h2><p>First, let&#39;s perform clustering using the Kmeans method.</p><pre><code class="nohighlight hljs">using CSV
using DataFrames
using HorseML.Clustering
using HorseML.Clustering: fit!

#Download this file from https://raw.githubusercontent.com/MommaWatasu/HorseML.jl/master/test/clustering.csv
x = CSV.read(&quot;clustering.csv&quot;, DataFrame, header = false) |&gt; Matrix

model = Kmeans(3)
fit!(model, x) # fitting
t = model.labels</code></pre><p>Let&#39;s visualize the results.</p><pre><code class="nohighlight hljs">using Plots

c1 = x[findall(t[:, 1].==1), :]
c2 = x[findall(t[:, 2].==1), :]
c3 = x[findall(t[:, 3].==1), :]

plot(c1[:, 1], c1[:, 2], seriestype = :scatter, title = &quot;Clusters&quot;)
plot!(c2[:, 1], c2[:, 2], seriestype = :scatter)
plot!(c3[:, 1], c3[:, 2], seriestype = :scatter)</code></pre><p><img src="../../assets/kmeans.png" alt="kmeans"/> To find the error, you need to use a different function than regression.</p><pre><code class="nohighlight hljs">using HorseML.LossFunction

dm(x, model(x), model.μ)</code></pre><p>The distortion measure should be used in this way as an exception.</p><h2 id="GMM(Gaussian-Mixture-Model)"><a class="docs-heading-anchor" href="#GMM(Gaussian-Mixture-Model)">GMM(Gaussian Mixture Model)</a><a id="GMM(Gaussian-Mixture-Model)-1"></a><a class="docs-heading-anchor-permalink" href="#GMM(Gaussian-Mixture-Model)" title="Permalink"></a></h2><p>If the cluster follows a Gaussian distribution, this technique is effective.</p><pre><code class="nohighlight hljs">model = GMM(3)
fit!(model, x) # fitting
model(x) # predicting</code></pre><p>The Gaussian Mixture Model also needs to use a different loss function.</p><pre><code class="nohighlight hljs">π, μ, Σ = model.π, model.μ, model.σ
nlh(x, π, μ, Σ)</code></pre><h2 id="Xmeans"><a class="docs-heading-anchor" href="#Xmeans">Xmeans</a><a id="Xmeans-1"></a><a class="docs-heading-anchor-permalink" href="#Xmeans" title="Permalink"></a></h2><p>You sometime want to cluster without the number of clusters. The Xmeans method makes it possible using Kmeans and BIC.</p><pre><code class="nohighlight hljs">#Download this file from https://raw.githubusercontent.com/MommaWatasu/HorseML.jl/master/test/clustering3.csv
x = CSV.read(&quot;clustering3.csv&quot;, DataFrame, header = false) |&gt; Matrix

model = Xmenas()
fit!(model, x)</code></pre><p>Let&#39;s visualize this as well</p><pre><code class="nohighlight hljs">using Plots

plot(title=&quot;Clustering by Xmeans&quot;)
for i in 1 : maximum(model.labels)
    c = findall(model.labels.==i)
    plot!(data[c, 1], data[c, 2], st=:scatter)
end
plot!()</code></pre><p><img src="../../assets/xmeans.png" alt="xmeans"/></p><h2 id="DBSCAN"><a class="docs-heading-anchor" href="#DBSCAN">DBSCAN</a><a id="DBSCAN-1"></a><a class="docs-heading-anchor-permalink" href="#DBSCAN" title="Permalink"></a></h2><p>Now let&#39;s deal with density-based clustering techniques. This is useful when the shape of the cluster is special. Instead of the number of clusters, DBSCAN requires the number of neighborhoods needed to grow the cluster and the maximum distance to the neighborhood.</p><pre><code class="nohighlight hljs">#Download this file from https://raw.githubusercontent.com/MommaWatasu/HorseML.jl/master/test/clustering2.csv
x = CSV.read(&quot;clustering2.csv&quot;, DataFrame) |&gt; Matrix
model = DBSCAN(0.3, 3)
result = model(x)</code></pre><p>then, see the result</p><pre><code class="nohighlight hljs">plot(title = &quot;Clustering by DBSCAN&quot;)
for i in -1 : maximum(result)
    X = data[findall(result.==i), :]
    plot!(X[:, 1], X[:, 2], st=:scatter)
end
plot!()</code></pre><p><img src="../../assets/dbscan.png" alt="dbscan"/></p><h2 id="HDBSCAN"><a class="docs-heading-anchor" href="#HDBSCAN">HDBSCAN</a><a id="HDBSCAN-1"></a><a class="docs-heading-anchor-permalink" href="#HDBSCAN" title="Permalink"></a></h2><p>Finally, we do hierarchical density clustering. This algorithm is complicated, so I won&#39;t explain it here (see <a href="Tutorial/@ref"><code>HDBSCAN</code></a>). I will only show you how to use it.</p><pre><code class="nohighlight hljs">model = HDBSCAN(5, 3)
fit!(model, x) #This data is the same to previous section</code></pre><p>Let&#39;s see the result</p><pre><code class="nohighlight hljs">plot(title = &quot;Clustering by HDBSCAN&quot;)
result = model.labels
for i in -1 : maximum(result)
    X = data[findall(result.==i), :]
    plot!(X[:, 1], X[:, 2], st=:scatter)
end
plot!()</code></pre><p><img src="../../assets/hdbscan.png" alt="hdbscan"/> Oh? The light blue dots are mixed, did you fail? No, this is the point that was dropped from the cluster as noise. The feature of HDBSCAN is that the cluster is not easily affected even if there is noise.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../Classifiers/">« Classifiers</a><a class="docs-footer-nextpage" href="../Tree/">Tree »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.16 on <span class="colophon-date" title="Wednesday 4 May 2022 01:48">Wednesday 4 May 2022</span>. Using Julia version 1.7.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
